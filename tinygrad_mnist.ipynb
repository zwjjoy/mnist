{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc92cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#inspired by https://github.com/Matuzas77/MNIST-0.17/blob/master/MNIST_final_solution.ipynb\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd(), 'test'))\n",
    "\n",
    "import numpy as np\n",
    "from tinygrad.tensor import Tensor, GPU\n",
    "from tinygrad.nn import BatchNorm2D\n",
    "from extra.utils import get_parameters\n",
    "from datasets import fetch_mnist\n",
    "from extra.training import train, evaluate, sparse_categorical_crossentropy\n",
    "import tinygrad.optim as optim\n",
    "from extra.augment import augment_img\n",
    "GPU = os.getenv(\"GPU\", None) is not None\n",
    "QUICK = os.getenv(\"QUICK\", None) is not None\n",
    "DEBUG = os.getenv(\"DEBUG\", None) is not None\n",
    "\n",
    "class SqueezeExciteBlock2D:\n",
    "    def __init__(self, filters):\n",
    "        self.filters = filters\n",
    "        self.weight1 = Tensor.uniform(self.filters, self.filters//32)\n",
    "        self.bias1 = Tensor.uniform(1,self.filters//32)\n",
    "        self.weight2 = Tensor.uniform(self.filters//32, self.filters)\n",
    "        self.bias2 = Tensor.uniform(1, self.filters)\n",
    "\n",
    "    def __call__(self, input):\n",
    "        se = input.avg_pool2d(kernel_size=(input.shape[2], input.shape[3])) #GlobalAveragePool2D\n",
    "        se = se.reshape(shape=(-1, self.filters))\n",
    "        se = se.dot(self.weight1) + self.bias1\n",
    "        se = se.relu()\n",
    "        se = se.dot(self.weight2) + self.bias2\n",
    "        se = se.sigmoid().reshape(shape=(-1,self.filters,1,1)) #for broadcasting\n",
    "        se = input.mul(se)\n",
    "        return se\n",
    "\n",
    "class ConvBlock:\n",
    "    def __init__(self, h, w, inp, filters=128, conv=3):\n",
    "        self.h, self.w = h, w\n",
    "        self.inp = inp\n",
    "        #init weights\n",
    "        self.cweights = [Tensor.uniform(filters, inp if i==0 else filters, conv, conv) for i in range(3)]\n",
    "        self.cbiases = [Tensor.uniform(1, filters, 1, 1) for i in range(3)]\n",
    "        #init layers\n",
    "        self._bn = BatchNorm2D(128, training=True)\n",
    "        self._seb = SqueezeExciteBlock2D(filters)\n",
    "\n",
    "    def __call__(self, input):\n",
    "        x = input.reshape(shape=(-1, self.inp, self.w, self.h))\n",
    "        for cweight, cbias in zip(self.cweights, self.cbiases):\n",
    "            x = x.pad2d(padding=[1,1,1,1]).conv2d(cweight).add(cbias).relu()\n",
    "        x = self._bn(x)\n",
    "        x = self._seb(x)\n",
    "        return x\n",
    "\n",
    "class BigConvNet:\n",
    "    def __init__(self):\n",
    "        self.conv = [ConvBlock(28,28,1), ConvBlock(28,28,128), ConvBlock(14,14,128)]\n",
    "        self.weight1 = Tensor.uniform(128,10)\n",
    "        self.weight2 = Tensor.uniform(128,10)\n",
    "\n",
    "    def parameters(self):\n",
    "        if DEBUG: #keeping this for a moment\n",
    "            pars = [par for par in get_parameters(self) if par.requires_grad]\n",
    "            no_pars = 0\n",
    "            for par in pars:\n",
    "                print(par.shape)\n",
    "                no_pars += np.prod(par.shape)\n",
    "            print('no of parameters', no_pars)\n",
    "            return pars\n",
    "        else:\n",
    "            return get_parameters(self)\n",
    "\n",
    "    def save(self, filename):\n",
    "        with open(filename+'.npy', 'wb') as f:\n",
    "            for par in get_parameters(self):\n",
    "                #if par.requires_grad:\n",
    "                np.save(f, par.cpu().data)\n",
    "\n",
    "    def load(self, filename):\n",
    "        with open(filename+'.npy', 'rb') as f:\n",
    "            for par in get_parameters(self):\n",
    "                #if par.requires_grad:\n",
    "                try:\n",
    "                    par.cpu().data[:] = np.load(f)\n",
    "                    if GPU:\n",
    "                        par.gpu()\n",
    "                except:\n",
    "                    print('Could not load parameter')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv[0](x)\n",
    "        x = self.conv[1](x)\n",
    "        x = x.avg_pool2d(kernel_size=(2,2))\n",
    "        x = self.conv[2](x)\n",
    "        x1 = x.avg_pool2d(kernel_size=(14,14)).reshape(shape=(-1,128)) #global\n",
    "        x2 = x.max_pool2d(kernel_size=(14,14)).reshape(shape=(-1,128)) #global\n",
    "        xo = x1.dot(self.weight1) + x2.dot(self.weight2)\n",
    "        return xo.logsoftmax()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lrs = [1e-4, 1e-5] if QUICK else [1e-3, 1e-4, 1e-5, 1e-5]\n",
    "    epochss = [2, 1] if QUICK else [13, 3, 3, 1]\n",
    "    BS = 32\n",
    "\n",
    "    lmbd = 0.00025\n",
    "    lossfn = lambda out,y: sparse_categorical_crossentropy(out, y) + lmbd*(model.weight1.abs() + model.weight2.abs()).sum()\n",
    "    X_train, Y_train, X_test, Y_test = fetch_mnist()\n",
    "    steps = len(X_train)//BS\n",
    "    np.random.seed(1337)\n",
    "    if QUICK:\n",
    "        steps = 1\n",
    "        X_test, Y_test = X_test[:BS], Y_test[:BS]\n",
    "\n",
    "    model = BigConvNet()\n",
    "\n",
    "    if len(sys.argv) > 1:\n",
    "        try:\n",
    "            model.load(sys.argv[1])\n",
    "            print('Loaded weights \"'+sys.argv[1]+'\", evaluating...')\n",
    "            evaluate(model, X_test, Y_test, BS=BS)\n",
    "        except:\n",
    "            print('could not load weights \"'+sys.argv[1]+'\".')\n",
    "\n",
    "    if GPU:\n",
    "        params = get_parameters(model)\n",
    "        [x.gpu_() for x in params]\n",
    "\n",
    "    for lr, epochs in zip(lrs, epochss):\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        for epoch in range(1,epochs+1):\n",
    "            #first epoch without augmentation\n",
    "            X_aug = X_train if epoch == 1 else augment_img(X_train)\n",
    "            train(model, X_aug, Y_train, optimizer, steps=steps, lossfn=lossfn, BS=BS)\n",
    "            accuracy = evaluate(model, X_test, Y_test, BS=BS)\n",
    "            model.save(f'examples/checkpoint{accuracy * 1e6:.0f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
